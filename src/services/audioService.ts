import { apiService } from './apiService';
import { BrowserAudioService } from './browserAudioService';

export interface AudioRecordingOptions {
  duration?: number;
  sampleRate?: number;
  channels?: number;
  format?: 'wav' | 'webm' | 'mp3';
  quality?: 'low' | 'medium' | 'high';
}

export interface AudioTranscriptionResult {
  success: boolean;
  transcript: string;
  error?: string;
}

export interface AudioDevice {
  deviceId: string;
  label: string;
  kind: string;
}

// –ê—É–¥–∏–æ —Å–µ—Ä–≤–∏—Å - —Ä–∞–±–æ—Ç–∞–µ—Ç –¢–û–õ–¨–ö–û –≤ –±—Ä–∞—É–∑–µ—Ä–µ
export class AudioService {
  private browserService: BrowserAudioService | null = null;
  private onProgress?: (progress: number) => void;
  private onLevelChange?: (level: number) => void;

  constructor() {
    console.log('üéµ AudioService: Constructor called');
  }

  /**
   * –ü–æ–ª—É—á–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä–Ω—ã–π —Å–µ—Ä–≤–∏—Å (—Å–æ–∑–¥–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ)
   */
  private getBrowserService(): BrowserAudioService {
    if (!this.browserService) {
      console.log('üéµ AudioService: Creating browser service...');
      this.browserService = new BrowserAudioService();
      console.log('‚úÖ AudioService: Browser service created');
    }
    return this.browserService;
  }

  /**
   * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É –∞—É–¥–∏–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ
   */
  async checkSupport(): Promise<{
    isBrowser: boolean;
    getUserMedia: boolean;
    mediaRecorder: boolean;
    audioContext: boolean;
    supportedFormats: string[];
  }> {
    try {
      const browserService = this.getBrowserService();
      return await browserService.checkSupport();
    } catch (error) {
      console.error('‚ùå AudioService: Failed to check support:', error);
      return {
        isBrowser: false,
        getUserMedia: false,
        mediaRecorder: false,
        audioContext: false,
        supportedFormats: []
      };
    }
  }

  /**
   * –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
   */
  async getAudioDevices(): Promise<AudioDevice[]> {
    try {
      const browserService = this.getBrowserService();
      return browserService.getAudioDevices();
    } catch (error) {
      console.error('‚ùå AudioService: Failed to get audio devices:', error);
      return [];
    }
  }

  /**
   * –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
   */
  async requestPermission(deviceId?: string): Promise<any> {
    const browserService = this.getBrowserService();
    return browserService.requestPermission(deviceId);
  }

  /**
   * –ù–∞—á–∏–Ω–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ
   */
  async startRecording(options: AudioRecordingOptions = {}): Promise<void> {
    const browserService = this.getBrowserService();
    
    // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
    if (this.onLevelChange) {
      browserService.setLevelChangeHandler(this.onLevelChange);
    }
    
    await browserService.startRecording(options);
  }

  /**
   * –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ
   */
  async stopRecording(): Promise<Blob> {
    const browserService = this.getBrowserService();
    return browserService.stopRecording();
  }

  /**
   * –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Ñ–∞–π–ª
   */
  async transcribeAudio(audioBlob: Blob): Promise<AudioTranscriptionResult> {
    try {
      const audioFile = new File([audioBlob], 'recording.webm', { 
        type: audioBlob.type 
      });

      const result = await apiService.transcribeAudio(audioFile);
      
      return {
        success: true,
        transcript: result.transcript
      };
    } catch (error) {
      console.error('‚ùå AudioService: Error transcribing audio:', error);
      return {
        success: false,
        transcript: '',
        error: `–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: ${error}`
      };
    }
  }

  /**
   * –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –∏–Ω—Ç–µ—Ä–≤—å—é —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
   */
  async transcribeInterviewAnswer(
    audioBlob: Blob, 
    interviewId: number, 
    questionId: number
  ): Promise<AudioTranscriptionResult> {
    try {
      const audioFile = new File([audioBlob], 'interview-answer.webm', { 
        type: audioBlob.type 
      });

      const result = await apiService.transcribeInterviewAnswer(
        audioFile, 
        interviewId, 
        questionId
      );
      
      return {
        success: result.success,
        transcript: result.formattedText
      };
    } catch (error) {
      console.error('‚ùå AudioService: Error transcribing interview answer:', error);
      return {
        success: false,
        transcript: '',
        error: `–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: ${error}`
      };
    }
  }

  /**
   * –ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∑–∞–ø–∏—Å–∏
   */
  async getRecordingStatus(): Promise<boolean> {
    try {
      const browserService = this.getBrowserService();
      return browserService.getRecordingStatus();
    } catch (error) {
      console.error('‚ùå AudioService: Error getting recording status:', error);
      return false;
    }
  }

  /**
   * –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
   */
  setProgressHandler(handler: (progress: number) => void): void {
    this.onProgress = handler;
  }

  /**
   * –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–∑–º–µ–Ω–µ–Ω–∏—è —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
   */
  setLevelChangeHandler(handler: (level: number) => void): void {
    this.onLevelChange = handler;
  }

  /**
   * –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã
   */
  async cleanup(): Promise<void> {
    if (this.browserService) {
      try {
        this.browserService.cleanup();
        console.log('‚úÖ AudioService: Browser resources cleaned up');
      } catch (error) {
        console.error('‚ùå AudioService: Error cleaning up browser resources:', error);
      }
    }
  }

  getCurrentFormat(): string {
    return this.browserService?.getCurrentFormat?.() || 'webm';
  }
}

// –õ–µ–Ω–∏–≤—ã–π —Å–∏–Ω–≥–ª—Ç–æ–Ω - —Å–æ–∑–¥–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –æ–±—Ä–∞—â–µ–Ω–∏–∏
let _audioService: AudioService | null = null;

export const audioService = {
  get instance(): AudioService {
    if (!_audioService) {
      console.log('üéµ AudioService: Creating lazy instance...');
      _audioService = new AudioService();
    }
    return _audioService;
  },
  
  // –ü—Ä–æ–∫—Å–∏—Ä—É–µ–º –≤—Å–µ –º–µ—Ç–æ–¥—ã –∫ —ç–∫–∑–µ–º–ø–ª—è—Ä—É
  checkSupport: () => audioService.instance.checkSupport(),
  getAudioDevices: () => audioService.instance.getAudioDevices(),
  requestPermission: (deviceId?: string) => audioService.instance.requestPermission(deviceId),
  startRecording: (options?: AudioRecordingOptions) => audioService.instance.startRecording(options),
  stopRecording: () => audioService.instance.stopRecording(),
  transcribeAudio: (audioBlob: Blob) => audioService.instance.transcribeAudio(audioBlob),
  transcribeInterviewAnswer: (audioBlob: Blob, interviewId: number, questionId: number) => 
    audioService.instance.transcribeInterviewAnswer(audioBlob, interviewId, questionId),
  getRecordingStatus: () => audioService.instance.getRecordingStatus(),
  setProgressHandler: (handler: (progress: number) => void) => audioService.instance.setProgressHandler(handler),
  setLevelChangeHandler: (handler: (level: number) => void) => audioService.instance.setLevelChangeHandler(handler),
  cleanup: () => audioService.instance.cleanup(),
  getCurrentFormat: () => audioService.instance.getCurrentFormat()
}; 