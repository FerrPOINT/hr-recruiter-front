import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Mic, Send, Loader2, CheckCircle, Mail, Globe, Users, Info, Headphones, Video, Briefcase, Phone } from 'lucide-react';
import { useParams } from 'react-router-dom';
import { apiService } from '../services/apiService';
// TODO: Add branding import when implementing brand styling
// import type { Branding } from '../client/models/branding';
import type { Position } from '../client/models/position';
import type { Candidate } from '../client/models/candidate';
import type { Interview } from '../client/models/interview';
import type { Question } from '../client/models/question';
import toast from 'react-hot-toast';

// --- UI CONSTANTS ---
const MIC_TEST_DURATION = 10; // 10 —Å–µ–∫—É–Ω–¥
const INTRO_MESSAGES = [
  { from: 'ai', text: '–ü—Ä–∏–≤–µ—Ç üëã' },
  { from: 'ai', text: '–Ø —Ç–≤–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä.' },
  { from: 'ai', text: '–Ø –∑–∞–¥–∞–º —Ç–µ–±–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤. –î–ª—è –æ—Ç–≤–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π –º–∏–∫—Ä–æ—Ñ–æ–Ω. –î–∞–≤–∞–π –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç.' },
  { from: 'ai', text: '–ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É ¬´–¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞¬ª, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω.' },
];

// --- AUDIO ENHANCEMENT CONSTANTS ---
const AUDIO_ENHANCEMENT_CONFIG = {
  // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —É—Å–∏–ª–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  gain: {
    value: 2.0, // –£—Å–∏–ª–µ–Ω–∏–µ –≤ 2 —Ä–∞–∑–∞
    minValue: 1.0,
    maxValue: 5.0
  },
  // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–º–ø—Ä–µ—Å—Å–∏–∏
  compression: {
    threshold: -24, // dB
    ratio: 4, // 4:1
    attack: 0.003, // 3ms
    release: 0.25 // 250ms
  },
  // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
  filtering: {
    lowPass: 8000, // Hz - —É–±–∏—Ä–∞–µ–º –≤—ã—Å–æ–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã
    highPass: 80,  // Hz - —É–±–∏—Ä–∞–µ–º –Ω–∏–∑–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã
    notch: 50      // Hz - —É–±–∏—Ä–∞–µ–º —Å–µ—Ç–µ–≤—ã–µ –ø–æ–º–µ—Ö–∏
  },
  // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏—è
  noiseReduction: {
    enabled: true,
    sensitivity: 0.1, // –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ —à—É–º—É
    smoothing: 0.8    // –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
  }
};

const icons = [<Globe className="h-6 w-6 text-orange-500" />, <Headphones className="h-6 w-6 text-orange-500" />, <Mic className="h-4 w-4 text-orange-500" />, <Info className="h-6 w-6 text-orange-500" />];

const InterviewSession: React.FC = () => {
  const params = useParams<{ sessionId: string }>();
  const [loading, setLoading] = useState(true);
  type InterviewStep = 'invite' | 'intro' | 'mic-test' | 'mic-test-done' | 'question' | 'final';
  const [step, setStep] = useState<InterviewStep>('invite');

  // Data states
  // TODO: Add branding state when implementing brand styling
  // const [branding, setBranding] = useState<Branding | null>(null);
  const [position, setPosition] = useState<Position | null>(null);
  const [candidate, setCandidate] = useState<Candidate | null>(null);
  const [interview, setInterview] = useState<Interview | null>(null);
  const [questions, setQuestions] = useState<Question[]>([]);
  const [checklist, setChecklist] = useState<{ icon: React.ReactNode, text: string }[]>([]);
  const [inviteInfo, setInviteInfo] = useState<{ language: string; questionsCount: number } | null>(null);
  const [interviewSettings, setInterviewSettings] = useState<{ answerTime: number; language: string; saveAudio: boolean; saveVideo: boolean; randomOrder: boolean; minScore: number } | null>(null);
  const [error, setError] = useState<string | null>(null);

  // Chat & Recording states
  const [messages, setMessages] = useState<{ from: string, text: string }[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [recordTimer, setRecordTimer] = useState(0);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [currentQuestion, setCurrentQuestion] = useState(0);
  const [consent, setConsent] = useState(false);
  const [readyForAnswer, setReadyForAnswer] = useState(false);
  const [interviewAnswerIds, setInterviewAnswerIds] = useState<string[]>([]);

  // Audio recording states
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const [isAudioSupported, setIsAudioSupported] = useState<boolean>(true);
  const [audioStream, setAudioStream] = useState<MediaStream | null>(null);
  const [audioContext, setAudioContext] = useState<AudioContext | null>(null);
  const [analyser, setAnalyser] = useState<AnalyserNode | null>(null);
  const [mediaRecorder, setMediaRecorder] = useState<MediaRecorder | null>(null);
  const [recordedChunks, setRecordedChunks] = useState<Blob[]>([]);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [currentMimeType, setCurrentMimeType] = useState<string>('audio/mp3');
  const [micTestResult, setMicTestResult] = useState<'pending' | 'success' | 'failed'>('pending');
  const [micTestTries, setMicTestTries] = useState(0);

  // Audio enhancement states
  const [gainNode, setGainNode] = useState<GainNode | null>(null);
  const [compressorNode, setCompressorNode] = useState<DynamicsCompressorNode | null>(null);
  const [lowPassFilter, setLowPassFilter] = useState<BiquadFilterNode | null>(null);
  const [highPassFilter, setHighPassFilter] = useState<BiquadFilterNode | null>(null);
  const [notchFilter, setNotchFilter] = useState<BiquadFilterNode | null>(null);
  const [audioEnhancementEnabled, setAudioEnhancementEnabled] = useState<boolean>(true);
  const [currentGainValue, setCurrentGainValue] = useState<number>(AUDIO_ENHANCEMENT_CONFIG.gain.value);
  const [audioQuality, setAudioQuality] = useState<'poor' | 'good' | 'excellent'>('good');

  const chatEndRef = useRef<HTMLDivElement | null>(null);

  const ICONS = {
    checklist: [<Video className="h-6 w-6 text-primary-500" />, <Headphones className="h-6 w-6 text-primary-500" />, <Mic className="h-6 w-6 text-primary-500" />, <Info className="h-6 w-6 text-primary-500" />],
    invite: {
      candidate: <Users className="h-5 w-5 mr-3 text-primary-200" />,
      language: <Globe className="h-5 w-5 mr-3 text-primary-200" />,
      questions: <Info className="h-5 w-5 mr-3 text-primary-200" />,
    }
  };

  // --- DATA FETCHING ---
  useEffect(() => {
    (async () => {
      setLoading(true);
      setError(null);
      try {
        const { sessionId } = params;
        console.log('Loading interview session with ID:', sessionId);
        if (!sessionId) {
          setError('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–µ—Å—Å–∏–∏.');
          setLoading(false);
          return;
        }
        console.log('Fetching interview data...');
        const interviewData = await apiService.getInterview(parseInt(sessionId));
        console.log('Interview data received:', interviewData);
        if (!interviewData) {
          setError('–°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.');
          setLoading(false);
          return;
        }
        // –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        const { interview, candidate: candidateData, position: positionData, questions } = interviewData as any;
        console.log('Extracted data:', { interview, candidate: candidateData, position: positionData, questions });
        if (!interview || !candidateData || !positionData) {
          setError('–ù–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤—å—é');
          setLoading(false);
          return;
        }
        setInterview(interview);
        const checklistData = [
          { text: '–í—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é –±—Ä–∞—É–∑–µ—Ä–∞ Chrome –∏–ª–∏ Edge' },
          { text: '–í–∞—à–∏ –∫–æ–ª–æ–Ω–∫–∏ –∏–ª–∏ –Ω–∞—É—à–Ω–∏–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã –∏ —Ä–∞–±–æ—Ç–∞—é—Ç' },
          { text: '–í–∞—à –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç' },
          { text: '–í—ã –≤ —Ç–∏—Ö–æ–º –ø–æ–º–µ—â–µ–Ω–∏–∏ –∏ –≥–æ—Ç–æ–≤—ã —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏' },
        ];
        setChecklist(checklistData.map((item: any, index: number) => ({ ...item, icon: ICONS.checklist[index] })));
        setInviteInfo({ language: '–†—É—Å—Å–∫–∏–π', questionsCount: questions?.length || 3 });
        setCandidate(candidateData || null);
        setPosition(positionData || null);
        setQuestions(questions || []);
        setInterviewSettings({
          answerTime: positionData?.answerTime || 60, // –±–µ—Ä–µ–º –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–ª–∏ 60 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
          language: positionData?.language || '–†—É—Å—Å–∫–∏–π',
          saveAudio: positionData?.saveAudio ?? true,
          saveVideo: positionData?.saveVideo ?? false,
          randomOrder: positionData?.randomOrder ?? false,
          minScore: positionData?.minScore || 0
        });
        
        console.log('Interview settings loaded:', {
          answerTime: positionData?.answerTime || 60,
          language: positionData?.language || '–†—É—Å—Å–∫–∏–π',
          saveAudio: positionData?.saveAudio ?? true,
          saveVideo: positionData?.saveVideo ?? false,
          randomOrder: positionData?.randomOrder ?? false,
          minScore: positionData?.minScore || 0
        });
      } catch (e) {
        console.error('Error loading interview session data:', e);
        setError(`–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: ${e instanceof Error ? e.message : '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}`);
      } finally {
        setLoading(false);
      }
    })();
  }, [params]);

  // Sleep-—Ñ—É–Ω–∫—Ü–∏—è
  function sleep(ms: number) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –æ–¥–Ω–æ–º—É —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
  async function pushMessagesWithDelay(msgsArr: { from: string, text: string }[]) {
    for (const msg of msgsArr) {
      setMessages(msgs => [...msgs, msg]);
      await sleep(1500);
    }
  }

  // Main flow handler
  const handleStart = async () => {
    setStep('intro');
    await pushMessagesWithDelay([
      { from: 'ai', text: `–ü—Ä–∏–≤–µ—Ç, ${candidate?.firstName || '–∫–∞–Ω–¥–∏–¥–∞—Ç'}! üëã` },
      { from: 'ai', text: '–Ø —Ç–≤–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é. –Ø –∑–∞–¥–∞–º —Ç–µ–±–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤.' },
      { from: 'ai', text: '–°–Ω–∞—á–∞–ª–∞ –¥–∞–≤–∞–π —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ç–≤–æ–π –º–∏–∫—Ä–æ—Ñ–æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç. –ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ.' },
    ]);
  };

  const handleMicTestStart = async () => {
    console.log('=== HANDLE MIC TEST START ===');
    console.log('Setting mic test timer to:', MIC_TEST_DURATION, 'seconds');
    setStep('mic-test');
    setRecordTimer(MIC_TEST_DURATION);
    setMicTestResult('pending');
    await startAudioRecording(true); // true = mic test
  };

  const handleMicTestStop = async () => {
    console.log('=== HANDLE MIC TEST STOP START ===');
    const audioBlob = await stopAudioRecording(true); // true = mic test
    console.log('Received audioBlob from stopAudioRecording:', audioBlob);
    console.log('AudioBlob size:', audioBlob?.size, 'bytes');
    
    if (audioBlob && audioBlob.size > 0) {
      console.log('AudioBlob is valid, checking quality...');
      const quality = await checkAudioQuality(audioBlob);
      console.log('Audio quality check result:', quality);
      
      if (!quality.hasSound) {
        console.log('No sound detected, marking test as failed');
        setMicTestResult('failed');
        setMicTestTries(t => t + 1);
        setStep('mic-test-done');
        await pushMessagesWithDelay([
          { from: 'ai', text: '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.' }
        ]);
        return;
      }
      
      console.log('Sound detected, proceeding with transcription...');
      const transcript = await transcribeAudio(audioBlob);
      console.log('Transcription result:', transcript);
      
      if (transcript && transcript.trim().length > 0 && !/^–æ—à–∏–±–∫–∞/i.test(transcript.trim())) {
        console.log('Transcription successful, marking test as success');
        setMicTestResult('success');
        setStep('mic-test-done');
        
        // –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —á–∞—Ç
        await pushMessagesWithDelay([
          { from: 'user', text: transcript },
          { from: 'ai', text: '–û—Ç–ª–∏—á–Ω–æ! –ú–∏–∫—Ä–æ—Ñ–æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.' },
          { from: 'ai', text: '–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫ –∏–Ω—Ç–µ—Ä–≤—å—é.' }
        ]);
      } else {
        console.log('Transcription failed or empty, marking test as failed');
        setMicTestResult('failed');
        setMicTestTries(t => t + 1);
        setStep('mic-test-done');
        await pushMessagesWithDelay([
          { from: 'ai', text: '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.' }
        ]);
      }
    } else {
      console.log('AudioBlob is invalid or empty, marking test as failed');
      setMicTestResult('failed');
      setMicTestTries(t => t + 1);
      setStep('mic-test-done');
      await pushMessagesWithDelay([
        { from: 'ai', text: '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.' }
      ]);
    }
    console.log('=== HANDLE MIC TEST STOP END ===');
  };

  const handleStartInterview = async () => {
    console.log('=== HANDLE START INTERVIEW ===');
    console.log('Questions state:', questions);
    console.log('Questions length:', questions?.length);
    console.log('Current step:', step);
    
    // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –æ—Ç —Ç–µ—Å—Ç–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∏–Ω—Ç–µ—Ä–≤—å—é
    cleanupAudioResources();
    
    setStep('question');
    setMessages([]); // Clear chat for questions
    if (questions && questions.length > 0) {
      console.log('Starting interview with questions');
      await pushMessagesWithDelay([
        { from: 'ai', text: `–û—Ç–ª–∏—á–Ω–æ, –Ω–∞—á–∏–Ω–∞–µ–º. –í–æ–ø—Ä–æ—Å 1 –∏–∑ ${questions.length}.` },
        { from: 'ai', text: questions[0].text || '–í–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω' }
      ]);
      setReadyForAnswer(true);
    } else {
      console.log('No questions available, ending interview');
      await pushMessagesWithDelay([
        { from: 'ai', text: '–î–ª—è —ç—Ç–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ–∫–∞ –Ω–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤. –ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ.' }
      ]);
      setStep('final');
    }
  };
  
  const handleStartRecording = async () => {
    console.log('=== HANDLE START RECORDING ===');
    console.log('Starting regular answer recording');
    setReadyForAnswer(false);
    await startAudioRecording(false); // false = regular recording
  };

  const handleStopRecording = async () => {
    console.log('=== HANDLE STOP RECORDING START ===');
    const audioBlob = await stopAudioRecording(false); // false = regular recording
    
    if (audioBlob && audioBlob.size > 0) {
      console.log('Audio blob exists for answer, size:', audioBlob.size);
      console.log('Calling transcribeInterviewAnswer for answer...');
      const transcript = await transcribeInterviewAnswer(audioBlob, currentQuestion);
      await pushMessagesWithDelay([{ from: 'user', text: transcript }]);
    } else {
      console.log('No audio blob available for answer');
      await pushMessagesWithDelay([{ from: 'user', text: '–û—Ç–≤–µ—Ç –Ω–µ –∑–∞–ø–∏—Å–∞–Ω' }]);
    }

    const nextQuestionIndex = currentQuestion + 1;
    if (nextQuestionIndex < questions.length) {
      setCurrentQuestion(nextQuestionIndex);
      await pushMessagesWithDelay([
        { from: 'ai', text: '–û—Ç–ª–∏—á–Ω–æ, —Å–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–≤–µ—Ç.' },
        { from: 'ai', text: `–°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å ${nextQuestionIndex + 1} –∏–∑ ${questions.length}:` },
        { from: 'ai', text: questions[nextQuestionIndex]?.text || '–í–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω' }
      ]);
      setReadyForAnswer(true);
    } else {
      setStep('final');
      await pushMessagesWithDelay([
        { from: 'ai', text: '–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à–∏ –æ—Ç–≤–µ—Ç—ã. –≠—Ç–æ –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å.' },
        { from: 'ai', text: '–ú—ã –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤–µ—Ä–Ω–µ–º—Å—è —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è.' },
        { from: 'ai', text: '–•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è! üëã' }
      ]);
    }
    console.log('=== HANDLE STOP RECORDING END ===');
  };
  
  // Timer effect
  useEffect(() => {
    if (!isRecording || recordTimer <= 0) return;
    const timerId = setTimeout(() => setRecordTimer(t => t - 1), 1000);
    if (recordTimer === 1) {
      if (step === 'mic-test') setTimeout(() => handleMicTestStop(), 1000);
      else if (step === 'question') setTimeout(() => handleStopRecording(), 1000);
    }
    return () => clearTimeout(timerId);
  }, [isRecording, recordTimer, step]);

  useEffect(() => {
    chatEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // Audio recording functions
  const initializeAudio = async (): Promise<MediaRecorder | null> => {
    try {
      console.log('Initializing enhanced audio with microphone amplification...');
      
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É getUserMedia
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('getUserMedia not supported');
      }
      
      // –£–ª—É—á—à–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –¥–ª—è –ª—É—á—à–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
          sampleRate: 48000, // –í—ã—Å–æ–∫–∞—è —á–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
          channelCount: 1,   // –ú–æ–Ω–æ –¥–ª—è –ª—É—á—à–µ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
          // –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –Ω–µ –≤—Å–µ–º–∏ –±—Ä–∞—É–∑–µ—Ä–∞–º–∏)
          ...(navigator.mediaDevices.getSupportedConstraints().sampleRate && {
            sampleRate: { ideal: 48000, min: 44100 }
          })
        } 
      });
      
      console.log('Enhanced audio stream obtained');
      setAudioStream(stream);
      
      // –°–æ–∑–¥–∞–µ–º AudioContext —Å –≤—ã—Å–æ–∫–æ–π —á–∞—Å—Ç–æ—Ç–æ–π –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏
      const context = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 48000,
        latencyHint: 'interactive'
      });
      
      // –°–æ–∑–¥–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑ MediaStream
      const source = context.createMediaStreamSource(stream);
      
      // –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É –∞—É–¥–∏–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–ª—è —É—Å–∏–ª–µ–Ω–∏—è
      let currentNode: AudioNode = source;
      
      // 1. High-pass —Ñ–∏–ª—å—Ç—Ä (—É–±–∏—Ä–∞–µ–º –Ω–∏–∑–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã)
      if (AUDIO_ENHANCEMENT_CONFIG.filtering.highPass > 0) {
        const highPass = context.createBiquadFilter();
        highPass.type = 'highpass';
        highPass.frequency.value = AUDIO_ENHANCEMENT_CONFIG.filtering.highPass;
        highPass.Q.value = 1.0;
        currentNode.connect(highPass);
        setHighPassFilter(highPass);
        currentNode = highPass;
        console.log('High-pass filter added:', AUDIO_ENHANCEMENT_CONFIG.filtering.highPass, 'Hz');
      }
      
      // 2. Notch —Ñ–∏–ª—å—Ç—Ä (—É–±–∏—Ä–∞–µ–º —Å–µ—Ç–µ–≤—ã–µ –ø–æ–º–µ—Ö–∏ 50Hz)
      if (AUDIO_ENHANCEMENT_CONFIG.filtering.notch > 0) {
        const notch = context.createBiquadFilter();
        notch.type = 'notch';
        notch.frequency.value = AUDIO_ENHANCEMENT_CONFIG.filtering.notch;
        notch.Q.value = 10.0;
        currentNode.connect(notch);
        setNotchFilter(notch);
        currentNode = notch;
        console.log('Notch filter added:', AUDIO_ENHANCEMENT_CONFIG.filtering.notch, 'Hz');
      }
      
      // 3. –ö–æ–º–ø—Ä–µ—Å—Å–æ—Ä (—É–ª—É—á—à–∞–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω)
      if (AUDIO_ENHANCEMENT_CONFIG.compression) {
        const compressor = context.createDynamicsCompressor();
        compressor.threshold.value = AUDIO_ENHANCEMENT_CONFIG.compression.threshold;
        compressor.ratio.value = AUDIO_ENHANCEMENT_CONFIG.compression.ratio;
        compressor.attack.value = AUDIO_ENHANCEMENT_CONFIG.compression.attack;
        compressor.release.value = AUDIO_ENHANCEMENT_CONFIG.compression.release;
        compressor.knee.value = 30;
        currentNode.connect(compressor);
        setCompressorNode(compressor);
        currentNode = compressor;
        console.log('Compressor added with ratio:', AUDIO_ENHANCEMENT_CONFIG.compression.ratio);
      }
      
      // 4. Gain node (—É—Å–∏–ª–µ–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞)
      const gain = context.createGain();
      gain.gain.value = currentGainValue;
      currentNode.connect(gain);
      setGainNode(gain);
      currentNode = gain;
      console.log('Gain node added with value:', currentGainValue);
      
      // 5. Low-pass —Ñ–∏–ª—å—Ç—Ä (—É–±–∏—Ä–∞–µ–º –≤—ã—Å–æ–∫–∏–µ —á–∞—Å—Ç–æ—Ç—ã)
      if (AUDIO_ENHANCEMENT_CONFIG.filtering.lowPass > 0) {
        const lowPass = context.createBiquadFilter();
        lowPass.type = 'lowpass';
        lowPass.frequency.value = AUDIO_ENHANCEMENT_CONFIG.filtering.lowPass;
        lowPass.Q.value = 1.0;
        currentNode.connect(lowPass);
        setLowPassFilter(lowPass);
        currentNode = lowPass;
        console.log('Low-pass filter added:', AUDIO_ENHANCEMENT_CONFIG.filtering.lowPass, 'Hz');
      }
      
      // 6. –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
      const analyserNode = context.createAnalyser();
      analyserNode.fftSize = 512; // –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
      analyserNode.smoothingTimeConstant = 0.8;
      analyserNode.minDecibels = -90;
      analyserNode.maxDecibels = -10;
      currentNode.connect(analyserNode);
      
      setAudioContext(context);
      setAnalyser(analyserNode);
      
      // –°–æ–∑–¥–∞–µ–º MediaStreamDestination –¥–ª—è –∑–∞–ø–∏—Å–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ
      const destination = context.createMediaStreamDestination();
      analyserNode.connect(destination);
      
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É –∫–æ–¥–µ–∫–æ–≤ - –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –≤—ã—Å–æ–∫–æ–º—É –∫–∞—á–µ—Å—Ç–≤—É
      const supportedMimeTypes = [
        'audio/webm;codecs=opus', // –õ—É—á—à–∏–π –∫–æ–¥–µ–∫ –¥–ª—è —Ä–µ—á–∏
        'audio/ogg;codecs=opus',  // –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
        'audio/webm',             // Fallback
        'audio/mp4',              // –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π
        'audio/wav'               // –ë–µ–∑ —Å–∂–∞—Ç–∏—è
      ];
      
      let mimeType = null;
      for (const type of supportedMimeTypes) {
        if (MediaRecorder.isTypeSupported(type)) {
          mimeType = type;
          console.log('Using supported MIME type for enhanced recording:', type);
          break;
        }
      }
      
      let recorder: MediaRecorder;
      
      if (mimeType) {
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫
        recorder = new MediaRecorder(destination.stream, { mimeType });
        console.log('Using enhanced MediaRecorder with MIME type:', mimeType);
        setCurrentMimeType(mimeType);
      } else {
        console.warn('No supported MIME types found, using default');
        recorder = new MediaRecorder(destination.stream);
        console.log('Using default MediaRecorder settings');
        setCurrentMimeType('audio/webm');
      }
      
      // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π
      recorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          console.log('Enhanced data available, size:', event.data.size);
          setRecordedChunks(prev => [...prev, event.data]);
        }
      };
      
      recorder.onstop = () => {
        console.log('=== ENHANCED MEDIA RECORDER ONSTOP ===');
        console.log('Recorded chunks count:', recordedChunks.length);
        const blob = new Blob(recordedChunks, { type: currentMimeType });
        console.log('Created enhanced audio blob, size:', blob.size, 'bytes, type:', currentMimeType);
        setAudioBlob(blob);
        setRecordedChunks([]);
      };
      
      setMediaRecorder(recorder);
      console.log('Enhanced audio initialization completed successfully');
      return recorder;
    } catch (error) {
      console.error('Error initializing enhanced audio:', error);
      setIsAudioSupported(false);
      toast.error('–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É —Å —É—Å–∏–ª–µ–Ω–∏–µ–º');
      return null;
    }
  };

  const startAudioRecording = async (isMicTest = false) => {
    console.log('=== START AUDIO RECORDING ===');
    console.log('isMicTest:', isMicTest);
    console.log('Current recordTimer:', recordTimer);
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É MediaRecorder
    if (!window.MediaRecorder) {
      console.error('MediaRecorder not supported');
      toast.error('–í–∞—à –±—Ä–∞—É–∑–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ');
      return;
    }
    
    let currentRecorder = mediaRecorder;
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—ã–π MediaRecorder
    if (!currentRecorder || currentRecorder.state === 'inactive') {
      console.log('Creating new MediaRecorder...');
      currentRecorder = await initializeAudio();
      if (!currentRecorder) {
        console.log('Failed to initialize audio');
        return;
      }
      // –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    if (currentRecorder && currentRecorder.state === 'inactive') {
      console.log('Starting mediaRecorder...');
      setRecordedChunks([]);
      setAudioBlob(null);
      currentRecorder.start();
      setIsRecording(true);
      
      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—ã—á–Ω–æ–π –∑–∞–ø–∏—Å–∏ –æ—Ç–≤–µ—Ç–æ–≤, –ù–ï –¥–ª—è —Ç–µ—Å—Ç–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
      if (!isMicTest && recordTimer === 0) {
        const answerTime = interviewSettings?.answerTime || 60;
        console.log('Setting record timer to:', answerTime, 'seconds (for regular answer recording)');
        setRecordTimer(answerTime);
      } else if (isMicTest) {
        console.log('Mic test mode - using existing timer value:', recordTimer, 'seconds');
      } else {
        console.log('Regular recording mode - using existing timer value:', recordTimer, 'seconds');
      }
      
      // –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
      const audioLevelInterval = setInterval(() => {
        analyzeAudioLevel();
        // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —É—Å–∏–ª–µ–Ω–∏–µ –∫–∞–∂–¥—ã–µ 2 —Å–µ–∫—É–Ω–¥—ã
        if (audioEnhancementEnabled) {
          adjustGainDynamically(50);
        }
      }, 100);
      
      // –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
      (window as any).audioLevelInterval = audioLevelInterval;
    } else {
      console.log('MediaRecorder not ready or already recording, state:', currentRecorder?.state);
    }

    // –î–ª—è –º–∏–∫—Ä–æ—Ç–µ—Å—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π –º–∞—Å—Å–∏–≤
    if (isMicTest) {
      const w = window as any;
      w._micTestChunks = [];
      console.log('Initialized mic test chunks array');
      
      if (currentRecorder) {
        currentRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            w._micTestChunks.push(event.data);
            console.log('Mic test chunk added, size:', event.data.size, 'total chunks:', w._micTestChunks.length);
          }
        };
        
        // –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É –¥–ª—è —Ç–µ—Å—Ç–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
        const dataInterval = setInterval(() => {
          if (currentRecorder && currentRecorder.state === 'recording') {
            currentRecorder.requestData();
          } else {
            clearInterval(dataInterval);
          }
        }, 1000);
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        (window as any).micTestDataInterval = dataInterval;
      }
    } else {
      // –î–ª—è –æ–±—ã—á–Ω–æ–π –∑–∞–ø–∏—Å–∏ —Ç–∞–∫–∂–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö
      const w = window as any;
      w._regularRecordingChunks = [];
      console.log('Initialized regular recording chunks array');
      
      if (currentRecorder) {
        currentRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            w._regularRecordingChunks.push(event.data);
            console.log('Regular recording chunk added, size:', event.data.size, 'total chunks:', w._regularRecordingChunks.length);
          }
        };
        
        // –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É –¥–ª—è –æ–±—ã—á–Ω–æ–π –∑–∞–ø–∏—Å–∏
        const dataInterval = setInterval(() => {
          if (currentRecorder && currentRecorder.state === 'recording') {
            currentRecorder.requestData();
          } else {
            clearInterval(dataInterval);
          }
        }, 1000);
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        (window as any).regularRecordingDataInterval = dataInterval;
      }
    }
  };

  const stopAudioRecording = async (isMicTest = false) => {
    console.log('=== STOP AUDIO RECORDING ===');
    console.log('isMicTest:', isMicTest);
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
    if ((window as any).audioLevelInterval) {
      clearInterval((window as any).audioLevelInterval);
      (window as any).audioLevelInterval = null;
      console.log('Audio level analysis stopped');
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –∑–∞–ø—Ä–æ—Å–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
    if (isMicTest && (window as any).micTestDataInterval) {
      clearInterval((window as any).micTestDataInterval);
      (window as any).micTestDataInterval = null;
      console.log('Mic test data interval stopped');
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª –∑–∞–ø—Ä–æ—Å–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ã—á–Ω–æ–π –∑–∞–ø–∏—Å–∏
    if (!isMicTest && (window as any).regularRecordingDataInterval) {
      clearInterval((window as any).regularRecordingDataInterval);
      (window as any).regularRecordingDataInterval = null;
      console.log('Regular recording data interval stopped');
    }
    
    // –ü–æ–ª—É—á–∞–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π mediaRecorder –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
    const currentRecorder = mediaRecorder;
    console.log('Current recorder state:', currentRecorder?.state);
    
    if (!currentRecorder || currentRecorder.state !== 'recording') {
      console.log('MediaRecorder not recording, state:', currentRecorder?.state);
      return null;
    }
    
    if (isMicTest) {
      // –î–ª—è —Ç–µ—Å—Ç–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º Promise
      console.log('Stopping mic test recording...');
      return new Promise<Blob>((resolve) => {
        const w = window as any;
        const micTestChunks = w._micTestChunks || [];
        console.log('Mic test chunks count:', micTestChunks.length);
        
        currentRecorder.onstop = () => {
          console.log('Mic test onstop triggered');
          // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π MIME —Ç–∏–ø
          const blob = new Blob(micTestChunks, { type: currentMimeType });
          console.log('Created mic test blob, size:', blob.size, 'bytes, type:', currentMimeType);
          setIsRecording(false);
          setRecordTimer(0);
          resolve(blob);
        };
        
        currentRecorder.stop();
      });
    } else {
      // –î–ª—è –æ–±—ã—á–Ω–æ–π –∑–∞–ø–∏—Å–∏
      console.log('Stopping regular recording...');
      return new Promise<Blob>((resolve) => {
        const w = window as any;
        const regularRecordingChunks = w._regularRecordingChunks || [];
        console.log('Regular recording chunks count:', regularRecordingChunks.length);
        
        currentRecorder.onstop = () => {
          console.log('Regular recording onstop triggered');
          // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π MIME —Ç–∏–ø
          const blob = new Blob(regularRecordingChunks, { type: currentMimeType });
          console.log('Created regular recording blob, size:', blob.size, 'bytes, type:', currentMimeType);
          setIsRecording(false);
          setRecordTimer(0);
          resolve(blob);
        };
        
        currentRecorder.stop();
      });
    }
  };

  // –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º —É—Å–∏–ª–µ–Ω–∏–µ–º
  const analyzeAudioLevel = () => {
    if (!analyser) return;
    
    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    analyser.getByteFrequencyData(dataArray);
    
    // –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º –∞–Ω–∞–ª–∏–∑–∞ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞
    let sum = 0;
    let count = 0;
    
    // –§–æ–∫—É—Å–∏—Ä—É–µ–º—Å—è –Ω–∞ —Ä–µ—á–µ–≤—ã—Ö —á–∞—Å—Ç–æ—Ç–∞—Ö (80Hz - 8000Hz)
    const speechFrequencies = dataArray.slice(2, Math.floor(dataArray.length * 0.8));
    
    for (let i = 0; i < speechFrequencies.length; i++) {
      if (speechFrequencies[i] > 0) {
        sum += speechFrequencies[i];
        count++;
      }
    }
    
    const average = count > 0 ? sum / count : 0;
    
    // –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫—É—é —à–∫–∞–ª—É –¥–ª—è –±–æ–ª–µ–µ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
    const normalizedLevel = Math.min(100, Math.pow(average / 255, 0.5) * 100 * 3);
    
    // –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —É—Å–∏–ª–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—É—â–µ–≥–æ —É—Ä–æ–≤–Ω—è
    let enhancedLevel = normalizedLevel;
    if (normalizedLevel < 20) {
      // –£—Å–∏–ª–∏–≤–∞–µ–º —Ç–∏—Ö–∏–µ –∑–≤—É–∫–∏
      enhancedLevel = normalizedLevel * 2;
    } else if (normalizedLevel > 80) {
      // –°–≥–ª–∞–∂–∏–≤–∞–µ–º –≥—Ä–æ–º–∫–∏–µ –∑–≤—É–∫–∏
      enhancedLevel = 80 + (normalizedLevel - 80) * 0.5;
    }
    
    setAudioLevel(enhancedLevel);
    
    // –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ
    if (enhancedLevel < 10) {
      setAudioQuality('poor');
    } else if (enhancedLevel < 30) {
      setAudioQuality('good');
    } else {
      setAudioQuality('excellent');
    }
  };

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ —É—Å–∏–ª–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  const adjustGainDynamically = (targetLevel: number = 50) => {
    if (!gainNode) return;
    
    const currentLevel = audioLevel;
    let newGain = currentGainValue;
    
    if (currentLevel < targetLevel * 0.5) {
      // –°–ª–∏—à–∫–æ–º —Ç–∏—Ö–æ - —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —É—Å–∏–ª–µ–Ω–∏–µ
      newGain = Math.min(AUDIO_ENHANCEMENT_CONFIG.gain.maxValue, currentGainValue * 1.2);
    } else if (currentLevel > targetLevel * 1.5) {
      // –°–ª–∏—à–∫–æ–º –≥—Ä–æ–º–∫–æ - —É–º–µ–Ω—å—à–∞–µ–º —É—Å–∏–ª–µ–Ω–∏–µ
      newGain = Math.max(AUDIO_ENHANCEMENT_CONFIG.gain.minValue, currentGainValue * 0.8);
    }
    
    if (newGain !== currentGainValue) {
      gainNode.gain.setValueAtTime(newGain, audioContext?.currentTime || 0);
      setCurrentGainValue(newGain);
      console.log('Dynamic gain adjustment:', currentGainValue, '->', newGain);
    }
  };

  // –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  const transcribeAudio = async (audioBlob: Blob): Promise<string> => {
    console.log('=== TRANSCRIBE AUDIO START ===');
    console.log('Audio blob size:', audioBlob.size, 'bytes');
    console.log('Audio blob type:', audioBlob.type);
    
    // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    if (audioBlob.size === 0) {
      console.error('Audio blob is empty');
      return '–ê—É–¥–∏–æ —Ñ–∞–π–ª –ø—É—Å—Ç';
    }
    
    if (audioBlob.size < 1024) { // –ú–µ–Ω—å—à–µ 1KB
      console.warn('Audio blob is very small, might be silent');
    }
    
    try {
      setIsTranscribing(true);
      
      // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ MIME —Ç–∏–ø–∞
      const getFileExtension = (mimeType: string) => {
        if (mimeType.includes('mp3') || mimeType.includes('mpeg')) return 'mp3';
        if (mimeType.includes('wav')) return 'wav';
        if (mimeType.includes('ogg')) return 'ogg';
        if (mimeType.includes('webm')) return 'webm';
        return 'mp3'; // fallback
      };
      
      const fileExtension = getFileExtension(audioBlob.type);
      const fileName = `recording.${fileExtension}`;
      
      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Blob –≤ File –¥–ª—è API
      const audioFile = new File([audioBlob], fileName, { type: audioBlob.type });
      console.log('Created audio file:', audioFile.name, audioFile.size, 'bytes, type:', audioFile.type);
      
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
      if (audioFile.size !== audioBlob.size) {
        console.error('File size mismatch:', audioFile.size, 'vs', audioBlob.size);
      }
      
      console.log('Calling apiService.transcribeAudio...');
      const response = await apiService.transcribeAudio(audioFile);
      console.log('Transcription response:', response);
      
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞, —á—Ç–æ –∏ –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é
      const transcript = response.transcript || '–¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω';
      console.log('Final transcript:', transcript);
      console.log('=== TRANSCRIBE AUDIO END ===');
      
      return transcript;
    } catch (error: any) {
      console.error('=== TRANSCRIBE AUDIO ERROR ===');
      console.error('Error transcribing audio:', error);
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);
      
      if (error.response) {
        console.error('Response status:', error.response.status);
        console.error('Response data:', error.response.data);
      }
      
      toast.error('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ');
      return '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏';
    } finally {
      setIsTranscribing(false);
    }
  };

  // –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∏–Ω—Ç–µ—Ä–≤—å—é —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
  const transcribeInterviewAnswer = async (audioBlob: Blob, questionIndex: number): Promise<string> => {
    console.log('=== TRANSCRIBE INTERVIEW ANSWER START ===');
    console.log('Audio blob size:', audioBlob.size, 'bytes');
    console.log('Question index:', questionIndex);
    
    // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    if (audioBlob.size === 0) {
      console.error('Audio blob is empty');
      return '–ê—É–¥–∏–æ —Ñ–∞–π–ª –ø—É—Å—Ç';
    }
    
    if (audioBlob.size < 1024) { // –ú–µ–Ω—å—à–µ 1KB
      console.warn('Audio blob is very small, might be silent');
    }
    
    try {
      setIsTranscribing(true);
      
      // –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ MIME —Ç–∏–ø–∞
      const getFileExtension = (mimeType: string) => {
        if (mimeType.includes('mp3') || mimeType.includes('mpeg')) return 'mp3';
        if (mimeType.includes('wav')) return 'wav';
        if (mimeType.includes('ogg')) return 'ogg';
        if (mimeType.includes('webm')) return 'webm';
        return 'mp3'; // fallback
      };
      
      const fileExtension = getFileExtension(audioBlob.type);
      const fileName = `recording.${fileExtension}`;
      
      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Blob –≤ File –¥–ª—è API
      const audioFile = new File([audioBlob], fileName, { type: audioBlob.type });
      console.log('Created audio file:', audioFile.name, audioFile.size, 'bytes, type:', audioFile.type);
      
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
      if (audioFile.size !== audioBlob.size) {
        console.error('File size mismatch:', audioFile.size, 'vs', audioBlob.size);
      }
      
      // –ü–æ–ª—É—á–∞–µ–º ID –∏–Ω—Ç–µ—Ä–≤—å—é –∏ –≤–æ–ø—Ä–æ—Å–∞
      const interviewId = parseInt(params.sessionId || '0');
      const questionId = questions[questionIndex]?.id || 0;
      
      console.log('Interview ID:', interviewId, 'Question ID:', questionId);
      
      if (!interviewId || !questionId) {
        throw new Error('Missing interview ID or question ID');
      }
      
      console.log('Calling apiService.transcribeInterviewAnswer...');
      const response = await apiService.transcribeInterviewAnswer(audioFile, interviewId, questionId);
      console.log('Interview answer transcription response:', response);
      
      // –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –æ—Ç–≤–µ—Ç–∞
      setInterviewAnswerIds(prev => {
        const newIds = [...prev];
        newIds[questionIndex] = response.interviewAnswerId;
        return newIds;
      });
      
      const transcript = response.formattedText || '–¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω';
      console.log('Final formatted transcript:', transcript);
      console.log('=== TRANSCRIBE INTERVIEW ANSWER END ===');
      
      return transcript;
    } catch (error: any) {
      console.error('=== TRANSCRIBE INTERVIEW ANSWER ERROR ===');
      console.error('Error transcribing interview answer:', error);
      console.error('Error message:', error.message);
      console.error('Error stack:', error.stack);
      
      if (error.response) {
        console.error('Response status:', error.response.status);
        console.error('Response data:', error.response.data);
      }
      
      toast.error('–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞');
      return '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏';
    } finally {
      setIsTranscribing(false);
    }
  };

  // –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–∏
  const checkAudioQuality = (audioBlob: Blob): Promise<{ hasSound: boolean; quality: 'good' | 'poor' | 'silent' }> => {
    return new Promise((resolve) => {
      const audio = new Audio();
      const url = URL.createObjectURL(audioBlob);
      
      audio.onloadedmetadata = () => {
        URL.revokeObjectURL(url);
        
        // –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å —É—á–µ—Ç–æ–º —É—Å–∏–ª–µ–Ω–∏—è
        const sizeInKB = audioBlob.size / 1024;
        const durationInSeconds = audio.duration;
        
        // –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        if (sizeInKB < 3 || durationInSeconds < 0.5) {
          resolve({ hasSound: false, quality: 'silent' });
        } else if (sizeInKB < 10 || durationInSeconds < 2) {
          resolve({ hasSound: true, quality: 'poor' });
        } else if (sizeInKB < 30) {
          resolve({ hasSound: true, quality: 'good' });
        } else {
          resolve({ hasSound: true, quality: 'good' });
        }
        
        console.log(`Audio quality check: ${sizeInKB.toFixed(1)}KB, ${durationInSeconds.toFixed(1)}s, gain: ${currentGainValue}x`);
      };
      
      audio.onerror = () => {
        URL.revokeObjectURL(url);
        resolve({ hasSound: false, quality: 'silent' });
      };
      
      audio.src = url;
    });
  };

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∞—É–¥–∏–æ —Ä–µ—Å—É—Ä—Å–æ–≤
  const cleanupAudioResources = () => {
    console.log('=== CLEANUP ENHANCED AUDIO RESOURCES ===');
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
    if ((window as any).audioLevelInterval) {
      clearInterval((window as any).audioLevelInterval);
      (window as any).audioLevelInterval = null;
      console.log('Audio level interval cleared');
    }
    
    if ((window as any).micTestDataInterval) {
      clearInterval((window as any).micTestDataInterval);
      (window as any).micTestDataInterval = null;
      console.log('Mic test data interval cleared');
    }
    
    if ((window as any).regularRecordingDataInterval) {
      clearInterval((window as any).regularRecordingDataInterval);
      (window as any).regularRecordingDataInterval = null;
      console.log('Regular recording data interval cleared');
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º MediaRecorder –µ—Å–ª–∏ –æ–Ω –∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç
    if (mediaRecorder && mediaRecorder.state === 'recording') {
      console.log('Stopping active MediaRecorder');
      mediaRecorder.stop();
    }
    
    // –û—Ç–∫–ª—é—á–∞–µ–º –≤—Å–µ –∞—É–¥–∏–æ —É–∑–ª—ã
    if (gainNode) {
      gainNode.disconnect();
      console.log('Gain node disconnected');
    }
    
    if (compressorNode) {
      compressorNode.disconnect();
      console.log('Compressor node disconnected');
    }
    
    if (lowPassFilter) {
      lowPassFilter.disconnect();
      console.log('Low-pass filter disconnected');
    }
    
    if (highPassFilter) {
      highPassFilter.disconnect();
      console.log('High-pass filter disconnected');
    }
    
    if (notchFilter) {
      notchFilter.disconnect();
      console.log('Notch filter disconnected');
    }
    
    // –ó–∞–∫—Ä—ã–≤–∞–µ–º AudioContext
    if (audioContext && audioContext.state !== 'closed') {
      console.log('Closing AudioContext');
      audioContext.close();
    }
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –≤—Å–µ —Ç—Ä–µ–∫–∏ –≤ MediaStream
    if (audioStream) {
      console.log('Stopping all audio tracks');
      audioStream.getTracks().forEach(track => {
        track.stop();
        console.log('Audio track stopped:', track.kind);
      });
    }
    
    // –û—á–∏—â–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è
    setMediaRecorder(null);
    setAudioContext(null);
    setAnalyser(null);
    setAudioStream(null);
    setGainNode(null);
    setCompressorNode(null);
    setLowPassFilter(null);
    setHighPassFilter(null);
    setNotchFilter(null);
    setRecordedChunks([]);
    setAudioBlob(null);
    setIsRecording(false);
    setRecordTimer(0);
    setAudioLevel(0);
    setCurrentGainValue(AUDIO_ENHANCEMENT_CONFIG.gain.value);
    setAudioQuality('good');
    
    console.log('Enhanced audio resources cleanup completed');
  };

  // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
  useEffect(() => {
    return () => {
      cleanupAudioResources();
    };
  }, []);

  // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —à–∞–≥–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
  useEffect(() => {
    if (step === 'final') {
      // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é
      setTimeout(() => {
        cleanupAudioResources();
      }, 1000); // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    }
  }, [step]);

  // --- RENDER ---
  if (loading) {
    return (
      <div className="flex items-center justify-center h-screen bg-gray-900">
        <div className="text-center">
          <Loader2 className="animate-spin h-12 w-12 text-primary-500 mx-auto mb-4" />
          <div className="text-white">–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é...</div>
        </div>
      </div>
    );
  }

  if (error) {
    return (
      <div className="flex items-center justify-center h-screen bg-gray-900">
        <div className="text-center">
          <div className="text-red-500 text-xl mb-4">{error}</div>
          <div className="text-gray-400 text-sm">sessionId: {params.sessionId}</div>
        </div>
      </div>
    );
  }

  if (!candidate || !position) {
    return (
      <div className="flex items-center justify-center h-screen bg-gray-900">
        <div className="text-center">
          <div className="text-red-500 text-xl mb-4">–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö</div>
          <div className="text-gray-400 text-sm">candidate: {candidate ? 'loaded' : 'null'}</div>
          <div className="text-gray-400 text-sm">position: {position ? 'loaded' : 'null'}</div>
          <div className="text-gray-400 text-sm">sessionId: {params.sessionId}</div>
        </div>
      </div>
    );
  }

  // Render welcome screen
  const renderWelcomeScreen = () => {
    if (!candidate || !position || step !== 'invite') return null;
    return (
      <div className="w-full max-w-2xl bg-gray-800/80 backdrop-blur-sm rounded-2xl shadow-2xl p-8 md:p-12 border border-gray-700">
        <div className="text-center mb-10">
          {/* TODO: Apply branding - use company name and logo from branding */}
          <span className="text-5xl font-extrabold tracking-tight text-wmt-orange mb-6 block">
            {'WMT –†–µ–∫—Ä—É—Ç–µ—Ä'}
          </span>
          {/* TODO: Apply branding - use primary/secondary colors from branding */}
          <h1 className="text-2xl font-semibold text-white leading-tight">
            –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø–æ–∑–∏—Ü–∏—é<br />
            <span className="text-3xl font-bold text-wmt-orange">"{position.title}"</span>
          </h1>
        </div>
        {/* TODO: Apply branding - use company styling for details section */}
        <div className="bg-gray-900/50 rounded-lg p-6 mb-8">
          <h2 className="font-semibold text-lg mb-6 text-center text-gray-300">–î–µ—Ç–∞–ª–∏</h2>
          <div className="grid grid-cols-3 gap-4 text-center divide-x divide-gray-600">
            <div className="px-2">
              <div className="text-sm text-gray-400 mb-1">–ö–∞–Ω–¥–∏–¥–∞—Ç</div>
              <div className="text-lg font-medium text-white truncate">{candidate.name}</div>
            </div>
            <div className="px-2">
              <div className="text-sm text-gray-400 mb-1">–Ø–∑—ã–∫</div>
              <div className="text-lg font-medium text-white">{inviteInfo?.language || '–†—É—Å—Å–∫–∏–π'}</div>
            </div>
            <div className="px-2">
              <div className="text-sm text-gray-400 mb-1">–í–æ–ø—Ä–æ—Å–æ–≤</div>
              <div className="text-lg font-medium text-white">{questions?.length ?? 0}</div>
            </div>
          </div>
        </div>
        {/* TODO: Apply branding - use company colors for checklist items */}
        <div className="mb-8">
          <h2 className="font-semibold text-lg mb-4 text-center text-gray-300">–ß–µ–∫-–ª–∏—Å—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏</h2>
          <ul className="space-y-3">
            {checklist.map((item, index) => (
              <li key={index} className="flex items-center text-gray-300 bg-gray-900/50 rounded-lg p-4">
                <div className="mr-4 text-wmt-orange">{item.icon}</div>
                <span>{item.text}</span>
              </li>
            ))}
          </ul>
        </div>
        {/* TODO: Apply branding - use company colors for consent checkbox */}
        <div className="flex items-start p-1 mb-6">
          <input
            id="consent"
            type="checkbox"
            checked={consent}
            onChange={(e) => setConsent(e.target.checked)}
            className="h-5 w-5 mt-0.5 flex-shrink-0 bg-gray-700 border-gray-600 rounded text-wmt-orange focus:ring-2 focus:ring-wmt-orange-dark focus:ring-offset-2 focus:ring-offset-gray-800"
          />
          <label htmlFor="consent" className="ml-3 text-sm text-gray-400">
            –Ø –¥–∞—é —Å–æ–≥–ª–∞—Å–∏–µ –Ω–∞ –∞—É–¥–∏–æ- –∏ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –º–æ–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
          </label>
        </div>
        {/* TODO: Apply branding - use company colors and styling for start button */}
        <button
          onClick={handleStart}
          disabled={!consent}
          className="w-full text-lg font-bold bg-wmt-orange hover:bg-wmt-orange-dark disabled:bg-gray-700 disabled:text-gray-400 disabled:cursor-not-allowed text-white py-4 rounded-xl transition-all duration-300 shadow-lg shadow-wmt-orange/20 hover:shadow-wmt-orange/40"
        >
          –ù–∞—á–∞—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ
        </button>
      </div>
    );
  };

  // Render questions progress
  const renderQuestionsProgress = () => {
    if (!questions?.length || step !== 'question') return null;
    return (
      <div className="bg-gray-50 border-b p-3 flex-shrink-0">
        <div className="flex items-center justify-between mb-1">
          <h3 className="text-sm font-medium text-gray-700">–ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è</h3>
          <span className="text-sm text-gray-500">
            –í–æ–ø—Ä–æ—Å {currentQuestion + 1} –∏–∑ {questions.length}
          </span>
        </div>
        <div className="w-full bg-gray-200 rounded-full h-2">
          <div
            className="bg-primary-500 h-2 rounded-full transition-all duration-300"
            style={{ width: `${((currentQuestion + 1) / questions.length) * 100}%` }}
          ></div>
        </div>
      </div>
    );
  };

  // --- MAIN RENDER ---
  return (
    <div className="min-h-screen bg-gray-900 py-8">
      <div className="max-w-4xl mx-auto px-4 flex items-center justify-center min-h-[calc(100vh-4rem)]">
        {/* Show welcome screen */}
        {(step as InterviewStep) === 'invite' && renderWelcomeScreen()}
        {/* Main content */}
        {(step as InterviewStep) !== 'invite' && (
          <div className="w-full bg-white rounded-lg shadow-sm overflow-hidden h-[calc(100vh-8rem)] flex flex-col">
            {/* Questions progress bar */}
            {renderQuestionsProgress()}
            {/* Chat messages */}
            <div className="p-4 space-y-4 flex-1 overflow-y-auto">
              {messages.map((message, index) => (
                <div
                  key={index}
                  className={`flex ${message.from === 'ai' ? 'justify-start' : 'justify-end'}`}
                >
                  <div
                    className={`rounded-lg px-4 py-2 max-w-[80%] ${
                      message.from === 'ai'
                        ? 'bg-gray-100 text-gray-800'
                        : 'bg-primary-500 text-white'
                    }`}
                  >
                    {message.text}
                  </div>
                </div>
              ))}
              <div ref={chatEndRef} />
            </div>
            {/* Controls */}
            <div className="border-t p-4 flex-shrink-0">
              {(step as InterviewStep) === 'intro' && (
                <button
                  onClick={handleMicTestStart}
                  className="w-full btn-primary py-3 flex items-center justify-center"
                >
                  <Mic className="h-5 w-5 mr-2" />
                  –¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                </button>
              )}
              {(step as InterviewStep) === 'mic-test' && isRecording && (
                <div className="flex items-center justify-center space-x-4">
                  <div className="flex items-center space-x-2">
                    <Mic className="h-6 w-6 text-red-500 animate-pulse" />
                    <span>–ó–∞–ø–∏—Å—å... {recordTimer}—Å</span>
                  </div>
                  <button
                    onClick={handleMicTestStop}
                    className="bg-red-500 hover:bg-red-600 text-white font-medium py-2 px-4 rounded-lg transition-colors duration-200 flex items-center"
                  >
                    <div className="w-3 h-3 bg-white rounded-sm mr-2"></div>
                    –°—Ç–æ–ø
                  </button>
                </div>
              )}
              {(step as InterviewStep) === 'mic-test' && isTranscribing && (
                <div className="flex items-center justify-center space-x-2">
                  <Loader2 className="h-6 w-6 animate-spin" />
                  <span>–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏...</span>
                </div>
              )}
              {(step as InterviewStep) === 'mic-test-done' && micTestResult === 'failed' && (
                <div className="space-y-4">
                  <button
                    onClick={handleMicTestStart}
                    className="w-full btn-primary py-3 flex items-center justify-center"
                  >
                    <Mic className="h-5 w-5 mr-2" />
                    –ü–æ–≤—Ç–æ—Ä–∏—Ç—å —Ç–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                  </button>
                  <div className="bg-yellow-50 border border-yellow-200 rounded-lg p-4">
                    <h4 className="font-medium text-yellow-800 mb-2">–°–æ–≤–µ—Ç—ã –¥–ª—è –ª—É—á—à–µ–π –∑–∞–ø–∏—Å–∏:</h4>
                    <ul className="text-sm text-yellow-700 space-y-1">
                      <li>‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç–µ —á–µ—Ç–∫–æ –∏ –≥—Ä–æ–º–∫–æ</li>
                      <li>‚Ä¢ –î–µ—Ä–∂–∏—Ç–µ—Å—å –±–ª–∏–∂–µ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É</li>
                      <li>‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –ø–æ–º–µ—â–µ–Ω–∏–∏ —Ç–∏—Ö–æ</li>
                      <li>‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ —Å–∏—Å—Ç–µ–º–µ</li>
                    </ul>
                  </div>
                </div>
              )}
              {(step as InterviewStep) === 'mic-test-done' && micTestResult === 'success' && (
                <button
                  onClick={handleStartInterview}
                  className="w-full btn-primary py-3"
                >
                  –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é
                </button>
              )}
              {(step as InterviewStep) === 'question' && !isRecording && !isTranscribing && !readyForAnswer && (
                <div className="flex items-center justify-center space-x-2">
                  <Loader2 className="h-6 w-6 animate-spin" />
                  <span>–û–∂–∏–¥–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞...</span>
                </div>
              )}
              {(step as InterviewStep) === 'question' && !isRecording && !isTranscribing && readyForAnswer && (
                <div className="space-y-4">
                  <button
                    onClick={handleStartRecording}
                    className="w-full btn-primary py-3"
                  >
                    –ó–∞–ø–∏—Å–∞—Ç—å –æ—Ç–≤–µ—Ç
                  </button>
                </div>
              )}
              {(step as InterviewStep) === 'question' && isRecording && (
                <div className="flex items-center justify-center space-x-4">
                  <div className="flex items-center space-x-2">
                    <Mic className="h-6 w-6 text-red-500 animate-pulse" />
                    <span>–ó–∞–ø–∏—Å—å... {recordTimer}—Å</span>
                  </div>
                  <button
                    onClick={handleStopRecording}
                    className="bg-red-500 hover:bg-red-600 text-white font-medium py-2 px-4 rounded-lg transition-colors duration-200 flex items-center"
                  >
                    <div className="w-3 h-3 bg-white rounded-sm mr-2"></div>
                    –°—Ç–æ–ø
                  </button>
                </div>
              )}
              {(step as InterviewStep) === 'question' && isTranscribing && (
                <div className="flex items-center justify-center space-x-2">
                  <Loader2 className="h-6 w-6 animate-spin" />
                  <span>–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏...</span>
                </div>
              )}
              {(step as InterviewStep) === 'final' && (
                <div className="text-center text-gray-600">
                  –ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –º–æ–∂–µ—Ç–µ –∑–∞–∫—Ä—ã—Ç—å –≤–∫–ª–∞–¥–∫—É
                </div>
              )}
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default InterviewSession;