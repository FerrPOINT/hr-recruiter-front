import React, { useState, useEffect, useRef, useCallback } from 'react';
import { Mic, Send, Loader2, CheckCircle, Mail, Globe, Users, Info, Headphones, Video, Briefcase, Phone } from 'lucide-react';
import { useParams } from 'react-router-dom';
import { apiService } from '../services/apiService';
import { audioService } from '../services/audioService';
// TODO: Add branding import when implementing brand styling
// import type { Branding } from '../client/models/branding';
import type { Position } from '../client/models/position';
import type { Candidate } from '../client/models/candidate';
import type { Interview } from '../client/models/interview';
import type { Question } from '../client/models/question';
import toast from 'react-hot-toast';

// --- UI CONSTANTS ---
const MIC_TEST_DURATION = 10; // 10 —Å–µ–∫—É–Ω–¥
const INTRO_MESSAGES = [
  { from: 'ai', text: '–ü—Ä–∏–≤–µ—Ç üëã' },
  { from: 'ai', text: '–Ø —Ç–≤–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä.' },
  { from: 'ai', text: '–Ø –∑–∞–¥–∞–º —Ç–µ–±–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤. –î–ª—è –æ—Ç–≤–µ—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É–π –º–∏–∫—Ä–æ—Ñ–æ–Ω. –î–∞–≤–∞–π –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç.' },
  { from: 'ai', text: '–ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É ¬´–¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞¬ª, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∏–∫—Ä–æ—Ñ–æ–Ω.' },
];

// --- AUDIO RECORDING CONSTANTS ---
const AUDIO_RECORDING_CONFIG = {
  quality: 'high' as const,
  format: 'webm' as const,
  sampleRate: 48000,
  channels: 1
};

const icons = [<Globe className="h-6 w-6 text-orange-500" />, <Headphones className="h-6 w-6 text-orange-500" />, <Mic className="h-4 w-4 text-orange-500" />, <Info className="h-6 w-6 text-orange-500" />];

const InterviewSession: React.FC = () => {
  const params = useParams<{ sessionId: string }>();
  const [loading, setLoading] = useState(true);
  type InterviewStep = 'invite' | 'intro' | 'mic-test' | 'mic-test-done' | 'question' | 'final';
  const [step, setStep] = useState<InterviewStep>('invite');

  // Data states
  // TODO: Add branding state when implementing brand styling
  // const [branding, setBranding] = useState<Branding | null>(null);
  const [position, setPosition] = useState<Position | null>(null);
  const [candidate, setCandidate] = useState<Candidate | null>(null);
  const [interview, setInterview] = useState<Interview | null>(null);
  const [questions, setQuestions] = useState<Question[]>([]);
  const [checklist, setChecklist] = useState<{ icon: React.ReactNode, text: string }[]>([]);
  const [inviteInfo, setInviteInfo] = useState<{ language: string; questionsCount: number } | null>(null);
  const [interviewSettings, setInterviewSettings] = useState<{ answerTime: number; language: string; saveAudio: boolean; saveVideo: boolean; randomOrder: boolean; minScore: number } | null>(null);
  const [error, setError] = useState<string | null>(null);

  // Chat & Recording states
  const [messages, setMessages] = useState<{ from: string, text: string }[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [recordTimer, setRecordTimer] = useState(0);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [currentQuestion, setCurrentQuestion] = useState(0);
  const [consent, setConsent] = useState(false);
  const [readyForAnswer, setReadyForAnswer] = useState(false);
  const [interviewAnswerIds, setInterviewAnswerIds] = useState<string[]>([]);

  // Audio recording states
  const [audioLevel, setAudioLevel] = useState<number>(0);
  const [isAudioSupported, setIsAudioSupported] = useState<boolean>(true);
  const [micTestResult, setMicTestResult] = useState<'pending' | 'success' | 'failed'>('pending');
  const [micTestTries, setMicTestTries] = useState(0);

  const chatEndRef = useRef<HTMLDivElement | null>(null);

  const ICONS = {
    checklist: [<Video className="h-6 w-6 text-primary-500" />, <Headphones className="h-6 w-6 text-primary-500" />, <Mic className="h-6 w-6 text-primary-500" />, <Info className="h-6 w-6 text-primary-500" />],
    invite: {
      candidate: <Users className="h-5 w-5 mr-3 text-primary-200" />,
      language: <Globe className="h-5 w-5 mr-3 text-primary-200" />,
      questions: <Info className="h-5 w-5 mr-3 text-primary-200" />,
    }
  };

  // --- DATA FETCHING ---
  useEffect(() => {
    (async () => {
      setLoading(true);
      setError(null);
      try {
        const { sessionId } = params;
        console.log('Loading interview session with ID:', sessionId);
        if (!sessionId) {
          setError('–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–µ—Å—Å–∏–∏.');
          setLoading(false);
          return;
        }
        console.log('Fetching interview data...');
        const interviewData = await apiService.getInterview(parseInt(sessionId));
        console.log('Interview data received:', interviewData);
        if (!interviewData) {
          setError('–°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.');
          setLoading(false);
          return;
        }
        // –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        const { interview, candidate: candidateData, position: positionData, questions } = interviewData as any;
        console.log('Extracted data:', { interview, candidate: candidateData, position: positionData, questions });
        if (!interview || !candidateData || !positionData) {
          setError('–ù–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤—å—é');
          setLoading(false);
          return;
        }
        setInterview(interview);
        const checklistData = [
          { text: '–í—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é –±—Ä–∞—É–∑–µ—Ä–∞ Chrome –∏–ª–∏ Edge' },
          { text: '–í–∞—à–∏ –∫–æ–ª–æ–Ω–∫–∏ –∏–ª–∏ –Ω–∞—É—à–Ω–∏–∫–∏ –≤–∫–ª—é—á–µ–Ω—ã –∏ —Ä–∞–±–æ—Ç–∞—é—Ç' },
          { text: '–í–∞—à –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç' },
          { text: '–í—ã –≤ —Ç–∏—Ö–æ–º –ø–æ–º–µ—â–µ–Ω–∏–∏ –∏ –≥–æ—Ç–æ–≤—ã —Å–∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏' },
        ];
        setChecklist(checklistData.map((item: any, index: number) => ({ ...item, icon: ICONS.checklist[index] })));
        setInviteInfo({ language: '–†—É—Å—Å–∫–∏–π', questionsCount: questions?.length || 3 });
        setCandidate(candidateData || null);
        setPosition(positionData || null);
        setQuestions(questions || []);
        setInterviewSettings({
          answerTime: positionData?.answerTime || 60, // –±–µ—Ä–µ–º –∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏ –∏–ª–∏ 60 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
          language: positionData?.language || '–†—É—Å—Å–∫–∏–π',
          saveAudio: positionData?.saveAudio ?? true,
          saveVideo: positionData?.saveVideo ?? false,
          randomOrder: positionData?.randomOrder ?? false,
          minScore: positionData?.minScore || 0
        });
        
        console.log('Interview settings loaded:', {
          answerTime: positionData?.answerTime || 60,
          language: positionData?.language || '–†—É—Å—Å–∫–∏–π',
          saveAudio: positionData?.saveAudio ?? true,
          saveVideo: positionData?.saveVideo ?? false,
          randomOrder: positionData?.randomOrder ?? false,
          minScore: positionData?.minScore || 0
        });
      } catch (e) {
        console.error('Error loading interview session data:', e);
        setError(`–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: ${e instanceof Error ? e.message : '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞'}`);
      } finally {
        setLoading(false);
      }
    })();
  }, [params]);

  // –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∞—É–¥–∏–æ –≤ –±—Ä–∞—É–∑–µ—Ä–µ
  useEffect(() => {
    const checkAudioSupport = async () => {
      try {
        const support = await audioService.checkSupport();
        console.log('Audio support check:', support);
        
        if (!support.isBrowser || !support.getUserMedia || !support.mediaRecorder) {
          console.warn('Audio APIs not supported in this environment');
          setIsAudioSupported(false);
        } else {
          setIsAudioSupported(true);
        }
      } catch (error) {
        console.error('Error checking audio support:', error);
        setIsAudioSupported(false);
      }
    };

    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É –∞—É–¥–∏–æ —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    if (!loading) {
      checkAudioSupport();
    }
  }, [loading]);

  // Sleep-—Ñ—É–Ω–∫—Ü–∏—è
  function sleep(ms: number) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ –æ–¥–Ω–æ–º—É —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
  async function pushMessagesWithDelay(msgsArr: { from: string, text: string }[]) {
    for (const msg of msgsArr) {
      setMessages(msgs => [...msgs, msg]);
      await sleep(1500);
    }
  }

  // Main flow handler
  const handleStart = async () => {
    setStep('intro');
    await pushMessagesWithDelay([
      { from: 'ai', text: `–ü—Ä–∏–≤–µ—Ç, ${candidate?.firstName || '–∫–∞–Ω–¥–∏–¥–∞—Ç'}! üëã` },
      { from: 'ai', text: '–Ø —Ç–≤–æ–π –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–Ω—Ç–µ—Ä–≤—å—é. –Ø –∑–∞–¥–∞–º —Ç–µ–±–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å–æ–≤.' },
      { from: 'ai', text: '–°–Ω–∞—á–∞–ª–∞ –¥–∞–≤–∞–π —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ç–≤–æ–π –º–∏–∫—Ä–æ—Ñ–æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç. –ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É –Ω–∏–∂–µ.' },
    ]);
  };

  const handleMicTestStart = async () => {
    console.log('=== HANDLE MIC TEST START ===');
    console.log('Setting mic test timer to:', MIC_TEST_DURATION, 'seconds');
    setStep('mic-test');
    setRecordTimer(MIC_TEST_DURATION);
    setMicTestResult('pending');
    await startAudioRecording(true); // true = mic test
  };

  const handleMicTestStop = async () => {
    console.log('=== HANDLE MIC TEST STOP START ===');
    const audioBlob = await stopAudioRecording(true); // true = mic test
    console.log('Received audioBlob from stopAudioRecording:', audioBlob);
    console.log('AudioBlob size:', audioBlob?.size, 'bytes');
    
    if (audioBlob && audioBlob.size > 0) {
      console.log('AudioBlob is valid, checking quality...');
      const quality = await checkAudioQuality(audioBlob);
      console.log('Audio quality check result:', quality);
      
      if (!quality.hasSound) {
        console.log('No sound detected, marking test as failed');
        setMicTestResult('failed');
        setMicTestTries(t => t + 1);
        setStep('mic-test-done');
        await pushMessagesWithDelay([
          { from: 'ai', text: '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.' }
        ]);
        return;
      }
      
      console.log('Sound detected, proceeding with transcription...');
      const transcript = await transcribeAudio(audioBlob);
      console.log('Transcription result:', transcript);
      
      if (transcript && transcript.trim().length > 0 && !/^–æ—à–∏–±–∫–∞/i.test(transcript.trim())) {
        console.log('Transcription successful, marking test as success');
        setMicTestResult('success');
        setStep('mic-test-done');
        
        // –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —á–∞—Ç
        await pushMessagesWithDelay([
          { from: 'user', text: transcript },
          { from: 'ai', text: '–û—Ç–ª–∏—á–Ω–æ! –ú–∏–∫—Ä–æ—Ñ–æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.' },
          { from: 'ai', text: '–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –ø–µ—Ä–µ—Ö–æ–¥–∏—Ç—å –∫ –∏–Ω—Ç–µ—Ä–≤—å—é.' }
        ]);
      } else {
        console.log('Transcription failed or empty, marking test as failed');
        setMicTestResult('failed');
        setMicTestTries(t => t + 1);
        setStep('mic-test-done');
        await pushMessagesWithDelay([
          { from: 'ai', text: '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.' }
        ]);
      }
    } else {
      console.log('AudioBlob is invalid or empty, marking test as failed');
      setMicTestResult('failed');
      setMicTestTries(t => t + 1);
      setStep('mic-test-done');
      await pushMessagesWithDelay([
        { from: 'ai', text: '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.' }
      ]);
    }
    console.log('=== HANDLE MIC TEST STOP END ===');
  };

  const handleStartInterview = async () => {
    console.log('=== HANDLE START INTERVIEW ===');
    console.log('Questions state:', questions);
    console.log('Questions length:', questions?.length);
    console.log('Current step:', step);
    
    // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –æ—Ç —Ç–µ—Å—Ç–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –∏–Ω—Ç–µ—Ä–≤—å—é
    cleanupAudioResources();
    
    setStep('question');
    setMessages([]); // Clear chat for questions
    if (questions && questions.length > 0) {
      console.log('Starting interview with questions');
      await pushMessagesWithDelay([
        { from: 'ai', text: `–û—Ç–ª–∏—á–Ω–æ, –Ω–∞—á–∏–Ω–∞–µ–º. –í–æ–ø—Ä–æ—Å 1 –∏–∑ ${questions.length}.` },
        { from: 'ai', text: questions[0].text || '–í–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω' }
      ]);
      setReadyForAnswer(true);
    } else {
      console.log('No questions available, ending interview');
      await pushMessagesWithDelay([
        { from: 'ai', text: '–î–ª—è —ç—Ç–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ–∫–∞ –Ω–µ—Ç –≤–æ–ø—Ä–æ—Å–æ–≤. –ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ.' }
      ]);
      setStep('final');
    }
  };
  
  const handleStartRecording = async () => {
    console.log('=== HANDLE START RECORDING ===');
    console.log('Starting regular answer recording');
    setReadyForAnswer(false);
    await startAudioRecording(false); // false = regular recording
  };

  const handleStopRecording = async () => {
    console.log('=== HANDLE STOP RECORDING START ===');
    const audioBlob = await stopAudioRecording(false); // false = regular recording
    
    if (audioBlob && audioBlob.size > 0) {
      console.log('Audio blob exists for answer, size:', audioBlob.size);
      console.log('Calling transcribeInterviewAnswer for answer...');
      const transcript = await transcribeInterviewAnswer(audioBlob, currentQuestion);
      await pushMessagesWithDelay([{ from: 'user', text: transcript }]);
    } else {
      console.log('No audio blob available for answer');
      await pushMessagesWithDelay([{ from: 'user', text: '–û—Ç–≤–µ—Ç –Ω–µ –∑–∞–ø–∏—Å–∞–Ω' }]);
    }

    const nextQuestionIndex = currentQuestion + 1;
    if (nextQuestionIndex < questions.length) {
      setCurrentQuestion(nextQuestionIndex);
      await pushMessagesWithDelay([
        { from: 'ai', text: '–û—Ç–ª–∏—á–Ω–æ, —Å–ø–∞—Å–∏–±–æ –∑–∞ –æ—Ç–≤–µ—Ç.' },
        { from: 'ai', text: `–°–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å ${nextQuestionIndex + 1} –∏–∑ ${questions.length}:` },
        { from: 'ai', text: questions[nextQuestionIndex]?.text || '–í–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω' }
      ]);
      setReadyForAnswer(true);
    } else {
      setStep('final');
      await pushMessagesWithDelay([
        { from: 'ai', text: '–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–∞—à–∏ –æ—Ç–≤–µ—Ç—ã. –≠—Ç–æ –±—ã–ª –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å.' },
        { from: 'ai', text: '–ú—ã –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏ –≤–µ—Ä–Ω–µ–º—Å—è —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é –≤ –±–ª–∏–∂–∞–π—à–µ–µ –≤—Ä–µ–º—è.' },
        { from: 'ai', text: '–•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è! üëã' }
      ]);
    }
    console.log('=== HANDLE STOP RECORDING END ===');
  };
  
  // Timer effect
  useEffect(() => {
    if (!isRecording || recordTimer <= 0) return;
    const timerId = setTimeout(() => setRecordTimer(t => t - 1), 1000);
    if (recordTimer === 1) {
      if (step === 'mic-test') setTimeout(() => handleMicTestStop(), 1000);
      else if (step === 'question') setTimeout(() => handleStopRecording(), 1000);
    }
    return () => clearTimeout(timerId);
  }, [isRecording, recordTimer, step]);

  useEffect(() => {
    chatEndRef.current?.scrollIntoView({ behavior: 'smooth' });
  }, [messages]);

  // Audio recording functions using universal AudioService
  const startAudioRecording = async (isMicTest = false) => {
    console.log('=== START AUDIO RECORDING ===');
    console.log('isMicTest:', isMicTest);
    
    // –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É –∞—É–¥–∏–æ –ø–µ—Ä–µ–¥ –∑–∞–ø–∏—Å—å—é
    if (!isAudioSupported) {
      console.error('Audio not supported in this environment');
      toast.error('–ê—É–¥–∏–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ –¥–∞–Ω–Ω–æ–π —Å—Ä–µ–¥–µ');
      return;
    }
    
    try {
      // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
      audioService.setLevelChangeHandler((level) => {
        setAudioLevel(level);
      });
      
      // –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å
      const duration = isMicTest ? MIC_TEST_DURATION : (interviewSettings?.answerTime || 60);
      await audioService.startRecording({
        ...AUDIO_RECORDING_CONFIG,
        duration
      });
      
      setIsRecording(true);
      setRecordTimer(duration);
      
      console.log('Audio recording started successfully');
    } catch (error) {
      console.error('Error starting audio recording:', error);
      toast.error('–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ');
      setIsAudioSupported(false);
    }
  };

  const stopAudioRecording = async (isMicTest = false): Promise<Blob | null> => {
    console.log('=== STOP AUDIO RECORDING ===');
    console.log('isMicTest:', isMicTest);
    
    try {
      const audioBlob = await audioService.stopRecording();
      setIsRecording(false);
      setRecordTimer(0);
      setAudioLevel(0);
      
      console.log('Audio recording stopped, blob size:', audioBlob.size);
      return audioBlob;
    } catch (error) {
      console.error('Error stopping audio recording:', error);
      toast.error('–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –∑–∞–ø–∏—Å–∏');
      setIsRecording(false);
      setRecordTimer(0);
      return null;
    }
  };



  // –ü—Ä–æ—Å—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  const transcribeAudio = async (audioBlob: Blob): Promise<string> => {
    console.log('=== TRANSCRIBE AUDIO START ===');
    console.log('Audio blob size:', audioBlob.size, 'bytes');
    
    if (audioBlob.size === 0) {
      console.error('Audio blob is empty');
      return '–ê—É–¥–∏–æ —Ñ–∞–π–ª –ø—É—Å—Ç';
    }
    
    try {
      setIsTranscribing(true);
      const result = await audioService.transcribeAudio(audioBlob);
      
      if (result.success) {
        console.log('Transcription successful:', result.transcript);
        return result.transcript;
      } else {
        console.error('Transcription failed:', result.error);
        toast.error('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ');
        return '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏';
      }
    } catch (error) {
      console.error('Error transcribing audio:', error);
      toast.error('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –∞—É–¥–∏–æ');
      return '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏';
    } finally {
      setIsTranscribing(false);
    }
  };

  // –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∏–Ω—Ç–µ—Ä–≤—å—é —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤ –ë–î
  const transcribeInterviewAnswer = async (audioBlob: Blob, questionIndex: number): Promise<string> => {
    console.log('=== TRANSCRIBE INTERVIEW ANSWER START ===');
    console.log('Audio blob size:', audioBlob.size, 'bytes');
    console.log('Question index:', questionIndex);
    
    if (audioBlob.size === 0) {
      console.error('Audio blob is empty');
      return '–ê—É–¥–∏–æ —Ñ–∞–π–ª –ø—É—Å—Ç';
    }
    
    try {
      setIsTranscribing(true);
      
      // –ü–æ–ª—É—á–∞–µ–º ID –∏–Ω—Ç–µ—Ä–≤—å—é –∏ –≤–æ–ø—Ä–æ—Å–∞
      const interviewId = parseInt(params.sessionId || '0');
      const questionId = questions[questionIndex]?.id || 0;
      
      if (!interviewId || !questionId) {
        throw new Error('Missing interview ID or question ID');
      }
      
      const result = await audioService.transcribeInterviewAnswer(audioBlob, interviewId, questionId);
      
      if (result.success) {
        console.log('Interview answer transcription successful:', result.transcript);
        return result.transcript;
      } else {
        console.error('Interview answer transcription failed:', result.error);
        toast.error('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞');
        return '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏';
      }
    } catch (error) {
      console.error('Error transcribing interview answer:', error);
      toast.error('–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞');
      return '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏';
    } finally {
      setIsTranscribing(false);
    }
  };

  // –£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∑–∞–ø–∏—Å–∏
  const checkAudioQuality = (audioBlob: Blob): Promise<{ hasSound: boolean; quality: 'good' | 'poor' | 'silent' }> => {
    return new Promise((resolve) => {
      const audio = new Audio();
      const url = URL.createObjectURL(audioBlob);
      
      audio.onloadedmetadata = () => {
        URL.revokeObjectURL(url);
        
        // –£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å —É—á–µ—Ç–æ–º —É—Å–∏–ª–µ–Ω–∏—è
        const sizeInKB = audioBlob.size / 1024;
        const durationInSeconds = audio.duration;
        
        // –ë–æ–ª–µ–µ —Ç–æ—á–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        if (sizeInKB < 3 || durationInSeconds < 0.5) {
          resolve({ hasSound: false, quality: 'silent' });
        } else if (sizeInKB < 10 || durationInSeconds < 2) {
          resolve({ hasSound: true, quality: 'poor' });
        } else if (sizeInKB < 30) {
          resolve({ hasSound: true, quality: 'good' });
        } else {
          resolve({ hasSound: true, quality: 'good' });
        }
        
        console.log(`Audio quality check: ${sizeInKB.toFixed(1)}KB, ${durationInSeconds.toFixed(1)}s`);
      };
      
      audio.onerror = () => {
        URL.revokeObjectURL(url);
        resolve({ hasSound: false, quality: 'silent' });
      };
      
      audio.src = url;
    });
  };

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –∞—É–¥–∏–æ —Ä–µ—Å—É—Ä—Å–æ–≤
  const cleanupAudioResources = async () => {
    console.log('=== CLEANUP AUDIO RESOURCES ===');
    
    try {
      await audioService.cleanup();
      setIsRecording(false);
      setRecordTimer(0);
      setAudioLevel(0);
      console.log('Audio resources cleanup completed');
    } catch (error) {
      console.error('Error during audio cleanup:', error);
    }
  };

  // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
  useEffect(() => {
    return () => {
      cleanupAudioResources();
    };
  }, []);

  // –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ —à–∞–≥–∞ –∏–Ω—Ç–µ—Ä–≤—å—é
  useEffect(() => {
    if (step === 'final') {
      // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –∏–Ω—Ç–µ—Ä–≤—å—é
      setTimeout(() => {
        cleanupAudioResources();
      }, 1000); // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Ç–µ–∫—É—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    }
  }, [step]);

  // --- RENDER ---
  if (loading) {
    return (
      <div className="flex items-center justify-center h-screen bg-gray-900">
        <div className="text-center">
          <Loader2 className="animate-spin h-12 w-12 text-primary-500 mx-auto mb-4" />
          <div className="text-white">–ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Ç–µ—Ä–≤—å—é...</div>
        </div>
      </div>
    );
  }

  if (error) {
    return (
      <div className="flex items-center justify-center h-screen bg-gray-900">
        <div className="text-center">
          <div className="text-red-500 text-xl mb-4">{error}</div>
          <div className="text-gray-400 text-sm">sessionId: {params.sessionId}</div>
        </div>
      </div>
    );
  }

  if (!candidate || !position) {
    return (
      <div className="flex items-center justify-center h-screen bg-gray-900">
        <div className="text-center">
          <div className="text-red-500 text-xl mb-4">–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö</div>
          <div className="text-gray-400 text-sm">candidate: {candidate ? 'loaded' : 'null'}</div>
          <div className="text-gray-400 text-sm">position: {position ? 'loaded' : 'null'}</div>
          <div className="text-gray-400 text-sm">sessionId: {params.sessionId}</div>
        </div>
      </div>
    );
  }

  // Render welcome screen
  const renderWelcomeScreen = () => {
    if (!candidate || !position || step !== 'invite') return null;
    return (
      <div className="w-full max-w-2xl bg-gray-800/80 backdrop-blur-sm rounded-2xl shadow-2xl p-8 md:p-12 border border-gray-700">
        <div className="text-center mb-10">
          {/* TODO: Apply branding - use company name and logo from branding */}
          <span className="text-5xl font-extrabold tracking-tight text-wmt-orange mb-6 block">
            {'WMT –†–µ–∫—Ä—É—Ç–µ—Ä'}
          </span>
          {/* TODO: Apply branding - use primary/secondary colors from branding */}
          <h1 className="text-2xl font-semibold text-white leading-tight">
            –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–∞ –ø–æ–∑–∏—Ü–∏—é<br />
            <span className="text-3xl font-bold text-wmt-orange">"{position.title}"</span>
          </h1>
        </div>
        {/* TODO: Apply branding - use company styling for details section */}
        <div className="bg-gray-900/50 rounded-lg p-6 mb-8">
          <h2 className="font-semibold text-lg mb-6 text-center text-gray-300">–î–µ—Ç–∞–ª–∏</h2>
          <div className="grid grid-cols-3 gap-4 text-center divide-x divide-gray-600">
            <div className="px-2">
              <div className="text-sm text-gray-400 mb-1">–ö–∞–Ω–¥–∏–¥–∞—Ç</div>
              <div className="text-lg font-medium text-white truncate">{candidate.name}</div>
            </div>
            <div className="px-2">
              <div className="text-sm text-gray-400 mb-1">–Ø–∑—ã–∫</div>
              <div className="text-lg font-medium text-white">{inviteInfo?.language || '–†—É—Å—Å–∫–∏–π'}</div>
            </div>
            <div className="px-2">
              <div className="text-sm text-gray-400 mb-1">–í–æ–ø—Ä–æ—Å–æ–≤</div>
              <div className="text-lg font-medium text-white">{questions?.length ?? 0}</div>
            </div>
          </div>
        </div>
        {/* TODO: Apply branding - use company colors for checklist items */}
        <div className="mb-8">
          <h2 className="font-semibold text-lg mb-4 text-center text-gray-300">–ß–µ–∫-–ª–∏—Å—Ç –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏</h2>
          <ul className="space-y-3">
            {checklist.map((item, index) => (
              <li key={index} className="flex items-center text-gray-300 bg-gray-900/50 rounded-lg p-4">
                <div className="mr-4 text-wmt-orange">{item.icon}</div>
                <span>{item.text}</span>
              </li>
            ))}
          </ul>
        </div>
        {/* TODO: Apply branding - use company colors for consent checkbox */}
        <div className="flex items-start p-1 mb-6">
          <input
            id="consent"
            type="checkbox"
            checked={consent}
            onChange={(e) => setConsent(e.target.checked)}
            className="h-5 w-5 mt-0.5 flex-shrink-0 bg-gray-700 border-gray-600 rounded text-wmt-orange focus:ring-2 focus:ring-wmt-orange-dark focus:ring-offset-2 focus:ring-offset-gray-800"
          />
          <label htmlFor="consent" className="ml-3 text-sm text-gray-400">
            –Ø –¥–∞—é —Å–æ–≥–ª–∞—Å–∏–µ –Ω–∞ –∞—É–¥–∏–æ- –∏ –≤–∏–¥–µ–æ–∑–∞–ø–∏—Å—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è, –∞ —Ç–∞–∫–∂–µ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É –º–æ–∏—Ö –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
          </label>
        </div>
        {/* TODO: Apply branding - use company colors and styling for start button */}
        <button
          onClick={handleStart}
          disabled={!consent}
          className="w-full text-lg font-bold bg-wmt-orange hover:bg-wmt-orange-dark disabled:bg-gray-700 disabled:text-gray-400 disabled:cursor-not-allowed text-white py-4 rounded-xl transition-all duration-300 shadow-lg shadow-wmt-orange/20 hover:shadow-wmt-orange/40"
        >
          –ù–∞—á–∞—Ç—å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ
        </button>
      </div>
    );
  };

  // Render questions progress
  const renderQuestionsProgress = () => {
    if (!questions?.length || step !== 'question') return null;
    return (
      <div className="bg-gray-50 border-b p-3 flex-shrink-0">
        <div className="flex items-center justify-between mb-1">
          <h3 className="text-sm font-medium text-gray-700">–ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è</h3>
          <span className="text-sm text-gray-500">
            –í–æ–ø—Ä–æ—Å {currentQuestion + 1} –∏–∑ {questions.length}
          </span>
        </div>
        <div className="w-full bg-gray-200 rounded-full h-2">
          <div
            className="bg-primary-500 h-2 rounded-full transition-all duration-300"
            style={{ width: `${((currentQuestion + 1) / questions.length) * 100}%` }}
          ></div>
        </div>
      </div>
    );
  };

  // --- MAIN RENDER ---
  return (
    <div className="min-h-screen bg-gray-900 py-8">
      <div className="max-w-4xl mx-auto px-4 flex items-center justify-center min-h-[calc(100vh-4rem)]">
        {/* Show welcome screen */}
        {(step as InterviewStep) === 'invite' && renderWelcomeScreen()}
        {/* Main content */}
        {(step as InterviewStep) !== 'invite' && (
          <div className="w-full bg-white rounded-lg shadow-sm overflow-hidden h-[calc(100vh-8rem)] flex flex-col">
            {/* Questions progress bar */}
            {renderQuestionsProgress()}
            {/* Chat messages */}
            <div className="p-4 space-y-4 flex-1 overflow-y-auto">
              {messages.map((message, index) => (
                <div
                  key={index}
                  className={`flex ${message.from === 'ai' ? 'justify-start' : 'justify-end'}`}
                >
                  <div
                    className={`rounded-lg px-4 py-2 max-w-[80%] ${
                      message.from === 'ai'
                        ? 'bg-gray-100 text-gray-800'
                        : 'bg-primary-500 text-white'
                    }`}
                  >
                    {message.text}
                  </div>
                </div>
              ))}
              <div ref={chatEndRef} />
            </div>
            {/* Controls */}
            <div className="border-t p-4 flex-shrink-0">
              {(step as InterviewStep) === 'intro' && (
                <button
                  onClick={handleMicTestStart}
                  className="w-full btn-primary py-3 flex items-center justify-center"
                >
                  <Mic className="h-5 w-5 mr-2" />
                  –¢–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                </button>
              )}
              {(step as InterviewStep) === 'mic-test' && isRecording && (
                <div className="flex items-center justify-center space-x-4">
                  <div className="flex items-center space-x-2">
                    <Mic className="h-6 w-6 text-red-500 animate-pulse" />
                    <span>–ó–∞–ø–∏—Å—å... {recordTimer}—Å</span>
                  </div>
                  <button
                    onClick={handleMicTestStop}
                    className="bg-red-500 hover:bg-red-600 text-white font-medium py-2 px-4 rounded-lg transition-colors duration-200 flex items-center"
                  >
                    <div className="w-3 h-3 bg-white rounded-sm mr-2"></div>
                    –°—Ç–æ–ø
                  </button>
                </div>
              )}
              {(step as InterviewStep) === 'mic-test' && isTranscribing && (
                <div className="flex items-center justify-center space-x-2">
                  <Loader2 className="h-6 w-6 animate-spin" />
                  <span>–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏...</span>
                </div>
              )}
              {(step as InterviewStep) === 'mic-test-done' && micTestResult === 'failed' && (
                <div className="space-y-4">
                  <button
                    onClick={handleMicTestStart}
                    className="w-full btn-primary py-3 flex items-center justify-center"
                  >
                    <Mic className="h-5 w-5 mr-2" />
                    –ü–æ–≤—Ç–æ—Ä–∏—Ç—å —Ç–µ—Å—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
                  </button>
                  <div className="bg-yellow-50 border border-yellow-200 rounded-lg p-4">
                    <h4 className="font-medium text-yellow-800 mb-2">–°–æ–≤–µ—Ç—ã –¥–ª—è –ª—É—á—à–µ–π –∑–∞–ø–∏—Å–∏:</h4>
                    <ul className="text-sm text-yellow-700 space-y-1">
                      <li>‚Ä¢ –ì–æ–≤–æ—Ä–∏—Ç–µ —á–µ—Ç–∫–æ –∏ –≥—Ä–æ–º–∫–æ</li>
                      <li>‚Ä¢ –î–µ—Ä–∂–∏—Ç–µ—Å—å –±–ª–∏–∂–µ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É</li>
                      <li>‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤ –ø–æ–º–µ—â–µ–Ω–∏–∏ —Ç–∏—Ö–æ</li>
                      <li>‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –≤ —Å–∏—Å—Ç–µ–º–µ</li>
                    </ul>
                  </div>
                </div>
              )}
              {(step as InterviewStep) === 'mic-test-done' && micTestResult === 'success' && (
                <button
                  onClick={handleStartInterview}
                  className="w-full btn-primary py-3"
                >
                  –ù–∞—á–∞—Ç—å –∏–Ω—Ç–µ—Ä–≤—å—é
                </button>
              )}
              {(step as InterviewStep) === 'question' && !isRecording && !isTranscribing && !readyForAnswer && (
                <div className="flex items-center justify-center space-x-2">
                  <Loader2 className="h-6 w-6 animate-spin" />
                  <span>–û–∂–∏–¥–∞–Ω–∏–µ –≤–æ–ø—Ä–æ—Å–∞...</span>
                </div>
              )}
              {(step as InterviewStep) === 'question' && !isRecording && !isTranscribing && readyForAnswer && (
                <div className="space-y-4">
                  <button
                    onClick={handleStartRecording}
                    className="w-full btn-primary py-3"
                  >
                    –ó–∞–ø–∏—Å–∞—Ç—å –æ—Ç–≤–µ—Ç
                  </button>
                </div>
              )}
              {(step as InterviewStep) === 'question' && isRecording && (
                <div className="flex items-center justify-center space-x-4">
                  <div className="flex items-center space-x-2">
                    <Mic className="h-6 w-6 text-red-500 animate-pulse" />
                    <span>–ó–∞–ø–∏—Å—å... {recordTimer}—Å</span>
                  </div>
                  <button
                    onClick={handleStopRecording}
                    className="bg-red-500 hover:bg-red-600 text-white font-medium py-2 px-4 rounded-lg transition-colors duration-200 flex items-center"
                  >
                    <div className="w-3 h-3 bg-white rounded-sm mr-2"></div>
                    –°—Ç–æ–ø
                  </button>
                </div>
              )}
              {(step as InterviewStep) === 'question' && isTranscribing && (
                <div className="flex items-center justify-center space-x-2">
                  <Loader2 className="h-6 w-6 animate-spin" />
                  <span>–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø–∏—Å–∏...</span>
                </div>
              )}
              {(step as InterviewStep) === 'final' && (
                <div className="text-center text-gray-600">
                  –ò–Ω—Ç–µ—Ä–≤—å—é –∑–∞–≤–µ—Ä—à–µ–Ω–æ, –º–æ–∂–µ—Ç–µ –∑–∞–∫—Ä—ã—Ç—å –≤–∫–ª–∞–¥–∫—É
                </div>
              )}
            </div>
          </div>
        )}
      </div>
    </div>
  );
};

export default InterviewSession;